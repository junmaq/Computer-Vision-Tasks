{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt \n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.2\n"
     ]
    }
   ],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get bags of SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code tranlated from James Hays's code for Computer Vision Fall 2019\n",
    "\n",
    "#This feature representation is described in the handout, lecture\n",
    "#materials, and Szeliski chapter 14.\n",
    "\n",
    "def get_bags_of_sifts(image_paths,des_size,vocab_size):\n",
    "    \n",
    "# Use SIFT from Open-CV library refer to the code below for help and update perameters\n",
    "# to install open-cv use following coomands\n",
    "# pip install opencv-python==3.4.2.16\n",
    "# pip install opencv-contrib-python==3.4.2.16    \n",
    "    \n",
    "    sift = cv2.xfeatures2d.SIFT_create(des_size) #specify how many maximum descriptors you want in the output \n",
    "    with open('vocab'+str(vocab_size )+'.pkl','rb') as f: vocab = pickle.load(f)\n",
    "    vocab_size=vocab.shape[0]\n",
    "    KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "    KNN.fit(vocab,np.arange(0,vocab_size))\n",
    "    image_feats=np.zeros((len(image_paths),vocab_size))\n",
    "    for k,img_path in enumerate(image_paths):\n",
    "        \n",
    "        im = Image.open(img_path)\n",
    "        img = np.array(im)\n",
    "        kp, des = sift.detectAndCompute(img, None)\n",
    "                \n",
    "        if des is None:\n",
    "            continue\n",
    "#         des=des/LA.norm(des,axis=1).reshape(-1,1)\n",
    "        bins=KNN.predict(des)\n",
    "        bag=np.bincount(bins,minlength=vocab_size)\n",
    "\n",
    "        bag=bag/np.sum(bag)\n",
    "\n",
    "        image_feats[k]=bag\n",
    "\n",
    "    \n",
    "    return image_feats\n",
    "\n",
    "# image_paths is an N x 1 cell array of strings where each string is an\n",
    "# image path on the file system.\n",
    "\n",
    "# This function assumes that 'vocab.pkl' exists and contains an N x 128\n",
    "# matrix 'vocab' where each row is a kmeans centroid or visual word. This\n",
    "# matrix is saved to disk rather than passed in a parameter to avoid\n",
    "# recomputing the vocabulary in every run.\n",
    "\n",
    "# image_feats is an N x d matrix, where d is the dimensionality of the\n",
    "# feature representation. In this case, d will equal the number of clusters\n",
    "# or equivalently the number of entries in each image's histogram\n",
    "# ('vocab_size') below.\n",
    "\n",
    "# You will want to construct SIFT features here in the same way you\n",
    "# did in build_vocabulary function (except for possibly changing the sampling\n",
    "# rate) and then assign each local feature to its nearest cluster center\n",
    "# and build a histogram indicating how many times each cluster was used.\n",
    "# Don't forget to normalize the histogram, or else a larger image with more\n",
    "# SIFT features will look very different from a smaller version of the same\n",
    "# image.\n",
    "\n",
    "#  SIFT_features is a 128 x N matrix of SIFT features\n",
    "#  note: there are smoothing parameters you can manipulate for sift function\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code tranlated from James Hays's code for Computer Vision Fall 2019\n",
    "\n",
    "#This function will sample SIFT descriptors from the training images,\n",
    "#cluster them with kmeans, and then return the cluster centers.\n",
    "\n",
    "def build_vocabulary(image_paths, vocab_size, samples, des_size):\n",
    "    DES=np.zeros((des_size,128))\n",
    "    sift = cv2.xfeatures2d.SIFT_create(des_size) #specify how many maximum descriptors you want in the output \n",
    "    \n",
    "    for i,j in tqdm(enumerate(np.random.choice(image_paths.shape[0],samples,replace=False))):\n",
    "\n",
    "        im = Image.open(image_paths[j])\n",
    "#         im.thumbnail((128,128), Image.ANTIALIAS) \n",
    "        img = np.array(im)\n",
    "\n",
    "        kp, des = sift.detectAndCompute(img, None)   \n",
    "        if i==0:\n",
    "            DES=des\n",
    "        if des is None:\n",
    "            continue\n",
    "            \n",
    "        des=des/LA.norm(des,axis=1).reshape(-1,1)\n",
    "        DES=np.concatenate((DES,des),0)\n",
    "        \n",
    "    kmeans = KMeans(n_clusters=vocab_size, random_state=0).fit(DES)\n",
    "    vocab=kmeans.cluster_centers_\n",
    " \n",
    "    return vocab\n",
    "# The inputs are 'image_paths', a N x 1 cell array of image paths, and\n",
    "# 'vocab_size' the size of the vocabulary.\n",
    "\n",
    "# The output 'vocab' should be vocab_size x 128. Each row is a cluster\n",
    "# centroid / visual word.\n",
    "\n",
    "\n",
    "# Load images from the training set. To save computation time, you don't\n",
    "# necessarily need to sample from all images, although it would be better\n",
    "# to do so. You can randomly sample the descriptors from each image to save\n",
    "# memory and speed up the clustering. \n",
    "\n",
    "# For each loaded image, get some SIFT features. You don't have to get as\n",
    "# many SIFT features as you will in get_bags_of_sift, because you're only\n",
    "# trying to get a representative sample here.\n",
    "\n",
    "# Once you have tens of thousands of SIFT features from many training\n",
    "# images, cluster them with kmeans. The resulting centroids are now your\n",
    "# visual word vocabulary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code tranlated from James Hays's code for Computer Vision Fall 2019\n",
    "\n",
    "#This function returns numpy arrays containing the file path for each train\n",
    "#and test image, with their labels \n",
    "\n",
    "def get_image_paths(data_path, categories):\n",
    "    train_image_paths, train_labels = [], []\n",
    "    for cat in categories:\n",
    "        imgs = glob.glob(data_path+'/train/'+cat+'/*.*')\n",
    "        train_image_paths = train_image_paths + imgs\n",
    "        train_labels = train_labels + [cat]*len(imgs)\n",
    "\n",
    "    test_image_paths, test_labels = [], []\n",
    "    for cat in os.listdir(data_path+'/test/'):\n",
    "        imgs = glob.glob(data_path+'/test/'+cat+'/*.*')\n",
    "        test_image_paths = test_image_paths + imgs\n",
    "        test_labels = test_labels + [cat]*len(imgs)\n",
    "\n",
    "    return np.array(train_image_paths), np.array(test_image_paths), np.array(train_labels), np.array(test_labels) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get tiny Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code tranlated from James Hays's code for Computer Vision Fall 2019\n",
    "\n",
    "#This feature is inspired by the simple tiny images used as features in \n",
    "#  80 million tiny images: a large dataset for non-parametric object and\n",
    "#  scene recognition. A. Torralba, R. Fergus, W. T. Freeman. IEEE\n",
    "#  Transactions on Pattern Analysis and Machine Intelligence, vol.30(11),\n",
    "#  pp. 1958-1970, 2008. http://groups.csail.mit.edu/vision/TinyImages/\n",
    "\n",
    "    \n",
    "\n",
    "def get_tiny_images(image_paths):\n",
    "    \n",
    "    image_feats=[]\n",
    "    for img_path in (image_paths):\n",
    "        img=imread(img_path)\n",
    "        img=resize(img,(16,16))\n",
    "        img=img.reshape(256)\n",
    "        img=(img-np.mean(img))\n",
    "#         img=img/LA.norm(img)\n",
    "#         img=img/np.max(img)\n",
    "        image_feats.append(img)\n",
    "        \n",
    "    return np.array(image_feats)\n",
    "# image_paths is an N x 1 cell array of strings where each string is an\n",
    "#  image path on the file system.\n",
    "# image_feats is an N x d matrix of resized and then vectorized tiny\n",
    "#  images. E.g. if the images are resized to 16x16, d would equal 256.\n",
    "\n",
    "# To build a tiny image feature, simply resize the original image to a very\n",
    "# small square resolution, e.g. 16x16. You can either resize the images to\n",
    "# square while ignoring their aspect ratio or you can crop the center\n",
    "# square portion out of each image. Making the tiny images zero mean and\n",
    "# unit length (normalizing them) will increase performance modestly.\n",
    "\n",
    "# suggested functions: imread, imresize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code tranlated from James Hays's code for Computer Vision Fall 2019\n",
    "\n",
    "#This function will predict the category for every test image by finding\n",
    "#the training image with most similar features. Instead of 1 nearest\n",
    "#neighbor, you can vote based on k nearest neighbors which will increase\n",
    "#performance (although you need to pick a reasonable value for k).\n",
    "\n",
    "def nearest_neighbor_classify(train_image_feats, train_labels, test_image_feats):\n",
    "    KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "    KNN.fit(train_image_feats,train_labels)\n",
    "    predicted_categories=[]\n",
    "    for i in range(test_image_feats.shape[0]):\n",
    "        predicted_categories.append(KNN.predict(test_image_feats[i].reshape(1,-1))[0])\n",
    "#     accuracy=KNN.score(test_feats,test_labels)\n",
    "    \n",
    "    return np.array(predicted_categories)\n",
    "# image_feats is an N x d matrix, where d is the dimensionality of the\n",
    "#  feature representation.\n",
    "# train_labels is an N x 1 cell array, where each entry is a string\n",
    "#  indicating the ground truth category for each training image.\n",
    "# test_image_feats is an M x d matrix, where d is the dimensionality of the\n",
    "#  feature representation. You can assume M = N unless you've modified the\n",
    "#  starter code.\n",
    "# predicted_categories is an M x 1 cell array, where each entry is a string\n",
    "#  indicating the predicted category for each test image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code tranlated from James Hays's code for Computer Vision Fall 2019\n",
    "\n",
    "#This function will train a linear SVM for every category (i.e. one vs all)\n",
    "#and then use the learned linear classifiers to predict the category of\n",
    "#every test image. Every test feature will be evaluated with all 15 SVMs\n",
    "#and the most confident SVM will \"win\". Confidence, or distance from the\n",
    "#margin, is W*X + B where '*' is the inner product or dot product and W and\n",
    "#B are the learned hyperplane parameters.\n",
    "\n",
    "def svm_classify(train_image_feats, train_labels, test_image_feats):\n",
    "    \n",
    "    \n",
    "    categories = list(set(train_labels))\n",
    "    num_categories = len(categories)\n",
    "    \n",
    "    #make an SVM classifier\n",
    "    clf = svm.LinearSVC()\n",
    "\n",
    "    #fit on the training data\n",
    "    #you need to put your own array names here\n",
    "    clf.fit(train_image_feats, train_labels)\n",
    "    \n",
    "    predicted_categories=[]\n",
    "    for i in range(test_image_feats.shape[0]):\n",
    "        predicted_categories.append(clf.predict(test_image_feats[i].reshape(1,-1)))\n",
    "            \n",
    "#     accuracy=clf.score(test_image_feats,test_labels)\n",
    "    return np.array(predicted_categories)\n",
    "# image_feats is an N x d matrix, where d is the dimensionality of the\n",
    "#  feature representation.\n",
    "# train_labels is an N x 1 cell array, where each entry is a string\n",
    "#  indicating the ground truth category for each training image.\n",
    "# test_image_feats is an M x d matrix, where d is the dimensionality of the\n",
    "#  feature representation. You can assume M = N unless you've modified the\n",
    "#  starter code.\n",
    "# predicted_categories is an M x 1 cell array, where each entry is a string\n",
    "#  indicating the predicted category for each test image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(5, 5)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "            TP += 1\n",
    "        elif y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "            FP += 1\n",
    "        elif y_actual[i]==y_hat[i]==0:\n",
    "            TN += 1\n",
    "        elif y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "            FN += 1\n",
    "\n",
    "    return [TP, FP, TN, FN]\n",
    "\n",
    "\n",
    "def display_results(test_labels, categories, predicted_categories):\n",
    "    df = pd.DataFrame(columns= ['Category']+list(categories))\n",
    "\n",
    "    cols = ['Category']+['TP', 'FP', 'TN', 'FN']\n",
    "    df = pd.DataFrame(columns= cols)\n",
    "    for el in categories:\n",
    "        temp_y_test = (test_labels == el).astype(int)\n",
    "        temp_preds = (predicted_categories == el).astype(int)\n",
    "        row = [el]+ perf_measure(temp_y_test, temp_preds)\n",
    "        df = df.append(pd.Series(row, index=cols), ignore_index=True)\n",
    "    print(df, '\\n\\n')\n",
    "\n",
    "    for i in range(len(categories)):\n",
    "        test_labels[test_labels==categories[i]] = i\n",
    "        predicted_categories[predicted_categories==categories[i]] = i\n",
    "    test_labels, predicted_categories = test_labels.astype(int), predicted_categories.astype(int)\n",
    "\n",
    "    class_names=np.array(categories)\n",
    "    plot_confusion_matrix(test_labels, predicted_categories, classes=class_names)\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(5, 5)\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    acc = accuracy_score(y_pred=predicted_categories, y_true=test_labels) #you need to put your own array names here\n",
    "    print('Accuracy: ', acc)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting paths and labels for all train and test data\n",
      "\n",
      "Using bag of sift representation for images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Starter code tranlated from James Hays's code for Computer Vision Fall 2019\n",
    "\n",
    "# All of your code will be in \"Step 1\" and \"Step 2\", although you can\n",
    "# modify other parameters in the starter code.\n",
    "\n",
    "## Step 0: Set up parameters, category list, and image paths.\n",
    "\n",
    "#For this Assignment, you will need to report performance for three\n",
    "#combinations of features / classifiers. It is suggested you code them in\n",
    "#this order, as well:\n",
    "# 1) Tiny image features and nearest neighbor classifier\n",
    "# 2) Bag of sift features and nearest neighbor classifier\n",
    "# 3) Bag of sift features and linear SVM classifier\n",
    "\n",
    "#The starter code is initialized to 'placeholder' just so that the starter\n",
    "#code does not crash when run unmodified and you can get a preview of how\n",
    "#results are presented.\n",
    "\n",
    "# FEATURE = 'tiny image'\n",
    "# FEATURE = 'bag of sift'\n",
    "FEATURE = 'bag of sift'\n",
    "calc_vocab=False\n",
    "des_size =100\n",
    "samples= 1500\n",
    "vocab_size = 400\n",
    "# CLASSIFIER = 'nearest neighbor'\n",
    "# CLASSIFIER = 'support vector machine'\n",
    "CLASSIFIER = 'nearest neighbor'\n",
    "\n",
    "data_path = '../data/'\n",
    "# data_path = '/home/junaid/Desktop/Third/Computer  Vision/assignments/Assignment_4_bag_of_words/4_bag_of_words/data'\n",
    "\n",
    "#This is the list of categories / directories to use. The categories are\n",
    "#somewhat sorted by similarity so that the confusion matrix looks more\n",
    "#structured (indoor and then urban and then rural).\n",
    "\n",
    "categories = np.array(['Kitchen', 'Store', 'Bedroom', 'LivingRoom', 'Office',\n",
    "              'Industrial', 'Suburb', 'InsideCity', 'TallBuilding', 'Street',\n",
    "              'Highway', 'OpenCountry', 'Coast', 'Mountain', 'Forest'])\n",
    "   \n",
    "# #This list of shortened category names is used later for visualization.\n",
    "abbr_categories = np.array(['Kit', 'Sto', 'Bed', 'Liv', 'Off', 'Ind', 'Sub',\n",
    "                   'Cty', 'Bld', 'St', 'HW', 'OC', 'Cst', 'Mnt', 'For'])\n",
    "    \n",
    "\n",
    "#This function returns cell arrays containing the file path for each train\n",
    "#and test image, as well as cell arrays with the label of each train and\n",
    "#test image. By default all four of these arrays will be 1500x1 where each\n",
    "#entry is a char array (or string).\n",
    "print('Getting paths and labels for all train and test data\\n')\n",
    "train_image_paths, test_image_paths, train_labels, test_labels = get_image_paths(data_path, categories)\n",
    "\n",
    "\n",
    "#   train_image_paths  1500x1   cell      \n",
    "#   test_image_paths   705x1    cell           \n",
    "#   train_labels       1500x1   cell         \n",
    "#   test_labels        705x1    cell          \n",
    "\n",
    "## Step 1: Represent each image with the appropriate feature\n",
    "# Each function to construct features should return an N x d matrix, where\n",
    "# N is the number of paths passed to the function and d is the \n",
    "# dimensionality of each image representation. See the starter code for\n",
    "# each function for more details.\n",
    "\n",
    "print(\"Using\",FEATURE, \"representation for images\\n\")\n",
    "\n",
    "\n",
    "if(FEATURE == 'tiny image'):\n",
    "    # Code get_tiny_images function above 1st\n",
    "    train_image_feats = get_tiny_images(train_image_paths);\n",
    "    test_image_feats  = get_tiny_images(test_image_paths);\n",
    "    pass\n",
    "elif(FEATURE == 'bag of sift'):\n",
    "    # Code build_vocabulary function 1st\n",
    "    if((not os.path.exists('./vocab.pkl')) or calc_vocab):\n",
    "        print('No existing visual word vocabulary found. Computing one from training images\\n')\n",
    "         #Larger values will work better (to a point) but be slower to compute\n",
    "        vocab=build_vocabulary(train_image_paths, vocab_size=vocab_size , samples=samples, des_size=des_size)\n",
    "        with open('vocab'+str(vocab_size )+'.pkl','wb') as f: pickle.dump(vocab, f)\n",
    "     # Code get_bags_of_sifts function\n",
    "#     train_image_feats = get_bags_of_sifts(train_image_paths,des_size=des_size,vocab_size=vocab_size)\n",
    "    test_image_feats  = get_bags_of_sifts(test_image_paths,des_size=des_size,vocab_size=vocab_size)\n",
    "        \n",
    "elif(FEATURE == 'placeholder'):\n",
    "    train_image_feats = []\n",
    "    test_image_feats = []\n",
    "        \n",
    "else:\n",
    "    print('Unknown feature type')\n",
    "\n",
    "\n",
    "# You should avoid recomputing the features while debugging the classifiers\n",
    "# so you need to 'save' and 'load' the features using pickle library\n",
    "\n",
    "## Step 2: Classify each test image by training and using the appropriate classifier\n",
    "#  to classify test features should return an N x 1 cell array,\n",
    "# where N is the number of test cases and each entry is a string indicating\n",
    "# the predicted category for each test image. Each entry in\n",
    "# 'predicted_categories' must be one of the 15 strings in 'categories',\n",
    "# 'train_labels', and 'test_labels'. See the starter code for each function\n",
    "# for more details.\n",
    "\n",
    "print('Using', CLASSIFIER, 'classifier to predict test set categories\\n')\n",
    "\n",
    "if(CLASSIFIER == 'nearest neighbor'):\n",
    "    # Code nearest_neighbor_classify function above\n",
    "    predicted_categories = nearest_neighbor_classify(train_image_feats, train_labels, test_image_feats)\n",
    "        \n",
    "elif(CLASSIFIER == 'support vector machine'):\n",
    "    # Code svm_classify function above\n",
    "    predicted_categories = svm_classify(train_image_feats, train_labels, test_image_feats)\n",
    "        \n",
    "elif(CLASSIFIER == 'placeholder'):\n",
    "    # The placeholder classifier simply predicts a random category for every test case\n",
    "    predicted_categories = np.random.permutation(test_labels)\n",
    "        \n",
    "else:\n",
    "     print('Unknown classifier type')\n",
    "\n",
    "\n",
    "\n",
    "## Step 3: Build a confusion matrix and score the recognition system\n",
    "# You do not need to code anything in this section. \n",
    "\n",
    "# If we wanted to evaluate our recognition method properly we would train\n",
    "# and test on many random splits of the data. You are not required to do so\n",
    "# for this project.\n",
    "\n",
    "# This function will plot confusion matrix and accuracy of your model\n",
    "display_results(test_labels, categories, predicted_categories)\n",
    "\n",
    "# Interpreting your performance with 100 training examples per category:\n",
    "#  accuracy  =   0 -> Your code is broken (probably not the classifier's\n",
    "#                     fault! A classifier would have to be amazing to\n",
    "#                     perform this badly).\n",
    "#  accuracy ~= .07 -> Your performance is chance. Something is broken or\n",
    "#                     you ran the starter code unchanged.\n",
    "#  accuracy ~= .20 -> Rough performance with tiny images and nearest\n",
    "#                     neighbor classifier. Performance goes up a few\n",
    "#                     percentage points with K-NN instead of 1-NN.\n",
    "#  accuracy ~= .20 -> Rough performance with tiny images and linear SVM\n",
    "#                     classifier. The linear classifiers will have a lot of\n",
    "#                     trouble trying to separate the classes and may be\n",
    "#                     unstable (e.g. everything classified to one category)\n",
    "#  accuracy ~= .50 -> Rough performance with bag of SIFT and nearest\n",
    "#                     neighbor classifier. Can reach .60 with K-NN and\n",
    "#                     different distance metrics.\n",
    "#  accuracy ~= .60 -> You've gotten things roughly correct with bag of\n",
    "#                     SIFT and a linear SVM classifier.\n",
    "#  accuracy >= .70 -> You've also tuned your parameters well. E.g. number\n",
    "#                     of clusters, SVM regularization, number of patches\n",
    "#                     sampled when building vocabulary, size and step for\n",
    "#                     dense SIFT features.\n",
    "#  accuracy >= .80 -> You've added in spatial information somehow or you've\n",
    "#                     added additional, complementary image features. This\n",
    "#                     represents state of the art in Lazebnik et al 2006.\n",
    "#  accuracy >= .85 -> You've done extremely well. This is the state of the\n",
    "#                     art in the 2010 SUN database paper from fusing many \n",
    "#                     features. Don't trust this number unless you actually\n",
    "#                     measure many random splits.\n",
    "#  accuracy >= .90 -> You used modern deep features trained on much larger\n",
    "#                     image databases.\n",
    "#  accuracy >= .96 -> You can beat a human at this task. This isn't a\n",
    "#                     realistic number. Some accuracy calculation is broken\n",
    "#                     or your classifier is cheating and seeing the test\n",
    "#                     labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
